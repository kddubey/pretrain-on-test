{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train: Literal[100] = 100\n",
    "num_tests: list[int] = [50, 100, 200, 500]\n",
    "accuracies_home_dir = \"accuracies_from_paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs: list[pl.DataFrame] = []\n",
    "for num_test in num_tests:\n",
    "    df = utils.load_all_accuracies(\n",
    "        os.path.join(accuracies_home_dir, f\"m{num_train}\"), num_test\n",
    "    ).with_columns(num_test=pl.lit(num_test))\n",
    "    df = df.select(\"num_test\").with_columns(df.select(pl.exclude(\"num_test\")))\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = pl.concat(dfs).sort([\"num_test\", \"lm_type\", \"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num_test</th><th>lm_type</th><th>mean</th><th>se</th></tr><tr><td>i32</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>50</td><td>&quot;bert&quot;</td><td>0.062064</td><td>0.007801</td></tr><tr><td>50</td><td>&quot;gpt2&quot;</td><td>0.021512</td><td>0.00647</td></tr><tr><td>100</td><td>&quot;bert&quot;</td><td>0.060996</td><td>0.007051</td></tr><tr><td>100</td><td>&quot;gpt2&quot;</td><td>0.024632</td><td>0.005623</td></tr><tr><td>200</td><td>&quot;bert&quot;</td><td>0.040692</td><td>0.007439</td></tr><tr><td>200</td><td>&quot;gpt2&quot;</td><td>0.062892</td><td>0.006661</td></tr><tr><td>500</td><td>&quot;bert&quot;</td><td>0.061296</td><td>0.00662</td></tr><tr><td>500</td><td>&quot;gpt2&quot;</td><td>0.038868</td><td>0.005375</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 4)\n",
       "┌──────────┬─────────┬──────────┬──────────┐\n",
       "│ num_test ┆ lm_type ┆ mean     ┆ se       │\n",
       "│ ---      ┆ ---     ┆ ---      ┆ ---      │\n",
       "│ i32      ┆ str     ┆ f64      ┆ f64      │\n",
       "╞══════════╪═════════╪══════════╪══════════╡\n",
       "│ 50       ┆ bert    ┆ 0.062064 ┆ 0.007801 │\n",
       "│ 50       ┆ gpt2    ┆ 0.021512 ┆ 0.00647  │\n",
       "│ 100      ┆ bert    ┆ 0.060996 ┆ 0.007051 │\n",
       "│ 100      ┆ gpt2    ┆ 0.024632 ┆ 0.005623 │\n",
       "│ 200      ┆ bert    ┆ 0.040692 ┆ 0.007439 │\n",
       "│ 200      ┆ gpt2    ┆ 0.062892 ┆ 0.006661 │\n",
       "│ 500      ┆ bert    ┆ 0.061296 ┆ 0.00662  │\n",
       "│ 500      ┆ gpt2    ┆ 0.038868 ┆ 0.005375 │\n",
       "└──────────┴─────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils._summarize_differences(\n",
    "    accuracy_df.with_columns(diff=pl.col(\"extra\") - pl.col(\"base\")),\n",
    "    groups=(\"num_test\", \"lm_type\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num_test</th><th>lm_type</th><th>mean</th><th>se</th></tr><tr><td>i32</td><td>str</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>50</td><td>&quot;bert&quot;</td><td>-0.000752</td><td>0.006085</td></tr><tr><td>50</td><td>&quot;gpt2&quot;</td><td>-0.000512</td><td>0.002824</td></tr><tr><td>100</td><td>&quot;bert&quot;</td><td>-0.003712</td><td>0.005826</td></tr><tr><td>100</td><td>&quot;gpt2&quot;</td><td>0.000268</td><td>0.002123</td></tr><tr><td>200</td><td>&quot;bert&quot;</td><td>0.003264</td><td>0.006085</td></tr><tr><td>200</td><td>&quot;gpt2&quot;</td><td>-0.000112</td><td>0.001992</td></tr><tr><td>500</td><td>&quot;bert&quot;</td><td>-0.001592</td><td>0.005723</td></tr><tr><td>500</td><td>&quot;gpt2&quot;</td><td>-0.002076</td><td>0.002078</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8, 4)\n",
       "┌──────────┬─────────┬───────────┬──────────┐\n",
       "│ num_test ┆ lm_type ┆ mean      ┆ se       │\n",
       "│ ---      ┆ ---     ┆ ---       ┆ ---      │\n",
       "│ i32      ┆ str     ┆ f64       ┆ f64      │\n",
       "╞══════════╪═════════╪═══════════╪══════════╡\n",
       "│ 50       ┆ bert    ┆ -0.000752 ┆ 0.006085 │\n",
       "│ 50       ┆ gpt2    ┆ -0.000512 ┆ 0.002824 │\n",
       "│ 100      ┆ bert    ┆ -0.003712 ┆ 0.005826 │\n",
       "│ 100      ┆ gpt2    ┆ 0.000268  ┆ 0.002123 │\n",
       "│ 200      ┆ bert    ┆ 0.003264  ┆ 0.006085 │\n",
       "│ 200      ┆ gpt2    ┆ -0.000112 ┆ 0.001992 │\n",
       "│ 500      ┆ bert    ┆ -0.001592 ┆ 0.005723 │\n",
       "│ 500      ┆ gpt2    ┆ -0.002076 ┆ 0.002078 │\n",
       "└──────────┴─────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils._summarize_differences(\n",
    "    accuracy_df.with_columns(diff=pl.col(\"test\") - pl.col(\"extra\")),\n",
    "    groups=(\"num_test\", \"lm_type\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
