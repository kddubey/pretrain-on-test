{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trains = (50, 100)\n",
    "num_tests = (50, 100, 200, 500)\n",
    "accuracies_home_dir: str = \"accuracies_from_paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for num_train in num_trains:\n",
    "    for num_test in num_tests:\n",
    "        dfs.append(\n",
    "            utils.load_all_accuracies(\n",
    "                os.path.join(accuracies_home_dir, f\"m{num_train}\"), num_test\n",
    "            ).with_columns(\n",
    "                pl.lit(num_train).alias(\"num_train\"), pl.lit(num_test).alias(\"num_test\")\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df: pl.DataFrame = pl.concat(dfs)\n",
    "\n",
    "group = [\"num_train\", \"num_test\", \"lm_type\", \"dataset\"]\n",
    "accuracies_df = accuracies_df.sort(by=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df = accuracies_df.with_columns(\n",
    "    pretraining_boost=pl.col(\"extra\") - pl.col(\"base\"),\n",
    "    evaluation_bias=pl.col(\"test\") - pl.col(\"extra\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sem(col: pl.Expr) -> pl.Expr:\n",
    "    # ty https://github.com/pola-rs/polars/issues/6175#issuecomment-1416846104\n",
    "    return col.std() / (col.count().sqrt())\n",
    "\n",
    "\n",
    "accuracies_grouped = (  # aggregate subsamples into mean and SE\n",
    "    accuracies_df.group_by(*group)\n",
    "    .agg(\n",
    "        pl.col(\"pretraining_boost\").mean().name.suffix(\"_mean\"),\n",
    "        sem(pl.col(\"pretraining_boost\")).name.suffix(\"_se\"),\n",
    "        pl.col(\"evaluation_bias\").mean().name.suffix(\"_mean\"),\n",
    "        sem(pl.col(\"evaluation_bias\")).name.suffix(\"_se\"),\n",
    "    )\n",
    "    .sort(group)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (400, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>num_train</th><th>num_test</th><th>lm_type</th><th>dataset</th><th>pretraining_boost_mean</th><th>pretraining_boost_se</th><th>evaluation_bias_mean</th><th>evaluation_bias_se</th></tr><tr><td>i32</td><td>i32</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>50</td><td>50</td><td>&quot;bert&quot;</td><td>&quot;FRENK-hate-en&quot;</td><td>-0.0264</td><td>0.009228</td><td>-0.0008</td><td>0.009551</td></tr><tr><td>50</td><td>50</td><td>&quot;bert&quot;</td><td>&quot;ag_news&quot;</td><td>0.1006</td><td>0.0098</td><td>-0.0162</td><td>0.011223</td></tr><tr><td>50</td><td>50</td><td>&quot;bert&quot;</td><td>&quot;amazon_counter…</td><td>0.0198</td><td>0.018692</td><td>0.0232</td><td>0.020512</td></tr><tr><td>50</td><td>50</td><td>&quot;bert&quot;</td><td>&quot;app_reviews&quot;</td><td>0.1186</td><td>0.012834</td><td>0.007</td><td>0.015615</td></tr><tr><td>50</td><td>50</td><td>&quot;bert&quot;</td><td>&quot;blog_authorshi…</td><td>-0.006</td><td>0.007001</td><td>0.0064</td><td>0.007638</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>100</td><td>500</td><td>&quot;gpt2&quot;</td><td>&quot;silicone&quot;</td><td>0.0352</td><td>0.009397</td><td>-0.0095</td><td>0.005943</td></tr><tr><td>100</td><td>500</td><td>&quot;gpt2&quot;</td><td>&quot;trec&quot;</td><td>0.0214</td><td>0.009417</td><td>-0.0009</td><td>0.00403</td></tr><tr><td>100</td><td>500</td><td>&quot;gpt2&quot;</td><td>&quot;tweets_hate_sp…</td><td>0.0233</td><td>0.027941</td><td>-0.0056</td><td>0.019901</td></tr><tr><td>100</td><td>500</td><td>&quot;gpt2&quot;</td><td>&quot;yahoo_answers_…</td><td>-0.0109</td><td>0.004161</td><td>-0.0015</td><td>0.002384</td></tr><tr><td>100</td><td>500</td><td>&quot;gpt2&quot;</td><td>&quot;yelp_review_fu…</td><td>-0.0355</td><td>0.007782</td><td>0.0014</td><td>0.002974</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (400, 8)\n",
       "┌───────────┬──────────┬─────────┬─────────────┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ num_train ┆ num_test ┆ lm_type ┆ dataset     ┆ pretrainin ┆ pretrainin ┆ evaluation ┆ evaluation │\n",
       "│ ---       ┆ ---      ┆ ---     ┆ ---         ┆ g_boost_me ┆ g_boost_se ┆ _bias_mean ┆ _bias_se   │\n",
       "│ i32       ┆ i32      ┆ str     ┆ str         ┆ an         ┆ ---        ┆ ---        ┆ ---        │\n",
       "│           ┆          ┆         ┆             ┆ ---        ┆ f64        ┆ f64        ┆ f64        │\n",
       "│           ┆          ┆         ┆             ┆ f64        ┆            ┆            ┆            │\n",
       "╞═══════════╪══════════╪═════════╪═════════════╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 50        ┆ 50       ┆ bert    ┆ FRENK-hate- ┆ -0.0264    ┆ 0.009228   ┆ -0.0008    ┆ 0.009551   │\n",
       "│           ┆          ┆         ┆ en          ┆            ┆            ┆            ┆            │\n",
       "│ 50        ┆ 50       ┆ bert    ┆ ag_news     ┆ 0.1006     ┆ 0.0098     ┆ -0.0162    ┆ 0.011223   │\n",
       "│ 50        ┆ 50       ┆ bert    ┆ amazon_coun ┆ 0.0198     ┆ 0.018692   ┆ 0.0232     ┆ 0.020512   │\n",
       "│           ┆          ┆         ┆ terfactual_ ┆            ┆            ┆            ┆            │\n",
       "│           ┆          ┆         ┆ en          ┆            ┆            ┆            ┆            │\n",
       "│ 50        ┆ 50       ┆ bert    ┆ app_reviews ┆ 0.1186     ┆ 0.012834   ┆ 0.007      ┆ 0.015615   │\n",
       "│ 50        ┆ 50       ┆ bert    ┆ blog_author ┆ -0.006     ┆ 0.007001   ┆ 0.0064     ┆ 0.007638   │\n",
       "│           ┆          ┆         ┆ ship_corpus ┆            ┆            ┆            ┆            │\n",
       "│ …         ┆ …        ┆ …       ┆ …           ┆ …          ┆ …          ┆ …          ┆ …          │\n",
       "│ 100       ┆ 500      ┆ gpt2    ┆ silicone    ┆ 0.0352     ┆ 0.009397   ┆ -0.0095    ┆ 0.005943   │\n",
       "│ 100       ┆ 500      ┆ gpt2    ┆ trec        ┆ 0.0214     ┆ 0.009417   ┆ -0.0009    ┆ 0.00403    │\n",
       "│ 100       ┆ 500      ┆ gpt2    ┆ tweets_hate ┆ 0.0233     ┆ 0.027941   ┆ -0.0056    ┆ 0.019901   │\n",
       "│           ┆          ┆         ┆ _speech_det ┆            ┆            ┆            ┆            │\n",
       "│           ┆          ┆         ┆ ection      ┆            ┆            ┆            ┆            │\n",
       "│ 100       ┆ 500      ┆ gpt2    ┆ yahoo_answe ┆ -0.0109    ┆ 0.004161   ┆ -0.0015    ┆ 0.002384   │\n",
       "│           ┆          ┆         ┆ rs_topics   ┆            ┆            ┆            ┆            │\n",
       "│ 100       ┆ 500      ┆ gpt2    ┆ yelp_review ┆ -0.0355    ┆ 0.007782   ┆ 0.0014     ┆ 0.002974   │\n",
       "│           ┆          ┆         ┆ _full       ┆            ┆            ┆            ┆            │\n",
       "└───────────┴──────────┴─────────┴─────────────┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────────────────┬────────────────────────┬─────────────────┐\n",
      "│ dataset                ┆ pretraining_boost_mean ┆ frac_boost_lt_0 │\n",
      "│ ---                    ┆ ---                    ┆ ---             │\n",
      "│ str                    ┆ f64                    ┆ f64             │\n",
      "╞════════════════════════╪════════════════════════╪═════════════════╡\n",
      "│ blog_authorship_corpus ┆ -0.009588              ┆ 0.625           │\n",
      "│ movie_rationales       ┆ -0.004675              ┆ 0.6875          │\n",
      "└────────────────────────┴────────────────────────┴─────────────────┘\n"
     ]
    }
   ],
   "source": [
    "with pl.Config(tbl_rows=-1):\n",
    "    print(\n",
    "        accuracies_grouped.group_by(\"dataset\")\n",
    "        .agg(  # across m, n, lm_type\n",
    "            pl.col(\"pretraining_boost_mean\").mean(),\n",
    "            (pl.col(\"pretraining_boost_mean\") < 0).mean().alias(\"frac_boost_lt_0\"),\n",
    "        )\n",
    "        .filter(pl.col(\"pretraining_boost_mean\") < 0)\n",
    "        .sort(\"pretraining_boost_mean\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (12, 3)\n",
      "┌────────────────────────────────┬──────────────────────┬────────────────┐\n",
      "│ dataset                        ┆ evaluation_bias_mean ┆ frac_bias_gt_0 │\n",
      "│ ---                            ┆ ---                  ┆ ---            │\n",
      "│ str                            ┆ f64                  ┆ f64            │\n",
      "╞════════════════════════════════╪══════════════════════╪════════════════╡\n",
      "│ amazon_counterfactual_en       ┆ 0.009306             ┆ 0.5625         │\n",
      "│ financial_phrasebank           ┆ 0.007406             ┆ 0.6875         │\n",
      "│ trec                           ┆ 0.002819             ┆ 0.5            │\n",
      "│ app_reviews                    ┆ 0.002575             ┆ 0.6875         │\n",
      "│ clickbait_notclickbait_dataset ┆ 0.0023625            ┆ 0.625          │\n",
      "│ craigslist_bargains            ┆ 0.0014               ┆ 0.6875         │\n",
      "│ emotion                        ┆ 0.001088             ┆ 0.6875         │\n",
      "│ climate_fever                  ┆ 0.001088             ┆ 0.5625         │\n",
      "│ blog_authorship_corpus         ┆ 0.001025             ┆ 0.6875         │\n",
      "│ limit                          ┆ 0.000987             ┆ 0.625          │\n",
      "│ disaster_response_messages     ┆ 0.000713             ┆ 0.375          │\n",
      "│ movie_rationales               ┆ 0.000381             ┆ 0.5625         │\n",
      "└────────────────────────────────┴──────────────────────┴────────────────┘\n"
     ]
    }
   ],
   "source": [
    "with pl.Config(tbl_rows=-1):\n",
    "    print(\n",
    "        accuracies_grouped.group_by(\"dataset\")\n",
    "        .agg(  # across m, n, lm_type\n",
    "            pl.col(\"evaluation_bias_mean\").mean(),\n",
    "            (pl.col(\"evaluation_bias_mean\") > 0).mean().alias(\"frac_bias_gt_0\"),\n",
    "        )\n",
    "        .filter(pl.col(\"evaluation_bias_mean\") > 0)\n",
    "        .sort(\"evaluation_bias_mean\", descending=True)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pretrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
